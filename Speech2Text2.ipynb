{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 14:46:41.452661: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-09 14:46:41.452758: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-09 14:46:41.452780: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-09 14:46:41.460032: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset, Audio, Dataset\n",
    "from datasets import concatenate_datasets\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from os import path, listdir\n",
    "from pydub import AudioSegment\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed https://keras.io/examples/audio/transformer_asr/\n",
    "and used \n",
    "https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_Tune_XLSR_Wav2Vec2_on_Common_Voice.ipynb#scrollTo=kAR0-2KLkopp\n",
    "to make adaptations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Swedish data\n",
    "#swedish = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"sv-SE\", cache_dir=\"data_swedish\", token=\"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\", num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download English data\n",
    "#english = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"en\", cache_dir=\"data_english\", token=\"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\", num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spanish Data\n",
    "#spanish = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"es\", cache_dir=\"data_spanish\", token=\"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\", num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish = load_dataset(\"/home/coder/projects/Audio Translate/Embedded-Project/data_spanish/mozilla-foundation___common_voice_12_0/es/12.0.0\")\n",
    "english = load_dataset(\"/home/coder/projects/Audio Translate/Embedded-Project/data_english/mozilla-foundation___common_voice_12_0/en/12.0.0\")\n",
    "swedish = load_dataset(\"/home/coder/projects/Audio Translate/Embedded-Project/data_swedish/mozilla-foundation___common_voice_12_0/sv-SE/12.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mp3_to_wav(batch):\n",
    "#    if(not path.exists(batch[\"path\"])):\n",
    "#        return batch\n",
    "#    sound = AudioSegment.from_mp3(batch[\"path\"])\n",
    "#    output_file = batch[\"path\"].split(\".\")[0]\n",
    "#    output_file = output_file + \".wav\"\n",
    "#    sound.export(output_file, format=\"wav\") \n",
    "#    os.remove(batch[\"path\"])\n",
    "#  \n",
    "#    return batch\n",
    "## Takes about 2 hours\n",
    "#english = english.map(mp3_to_wav, desc=\"prepare_sentences\", num_proc=32)\n",
    "#spanish = spanish.map(mp3_to_wav, desc=\"prepare_sentences\", num_proc=32)\n",
    "#swedish = swedish.map(mp3_to_wav, desc=\"prepare_sentences\", num_proc=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = concatenate_datasets([spanish[\"train\"].select(range(7421)), english[\"train\"].select(range(7421)), swedish[\"train\"].select(range(7421))])\n",
    "val_data = concatenate_datasets([spanish[\"validation\"].select(range(2000)), english[\"validation\"].select(range(2000)), swedish[\"validation\"].select(range(2000))])\n",
    "train_data = concatenate_datasets([train_data, val_data])\n",
    "test_data = concatenate_datasets([spanish[\"test\"].select(range(5091)), english[\"test\"].select(range(5091)), swedish[\"test\"].select(range(5091))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.remove_columns([\"path\", \"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])\n",
    "test_data = test_data.remove_columns([\"path\", \"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_weird(batch):\n",
    "    tmp = re.findall(\"[^a-zA-ZáéíóúüñÁÉÍÓÚÜÑåäöÄÅÖ '.,¿¡\\!?#<:;\\\"\\-]\", batch[\"sentence\"])\n",
    "    if(len(tmp) == 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'sentence', 'text'],\n",
      "    num_rows: 28263\n",
      "})\n",
      "Dataset({\n",
      "    features: ['audio', 'sentence', 'text'],\n",
      "    num_rows: 15273\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def prepare_sentences(batch):\n",
    "  \"\"\"Function to preprocess the dataset with the .map method\"\"\"\n",
    "  transcription = batch[\"sentence\"]\n",
    "  if transcription.startswith('\"') and transcription.endswith('\"'):\n",
    "    # we can remove trailing quotation marks as they do not affect the transcription\n",
    "    transcription = transcription[1:-1]\n",
    "  \n",
    "  if transcription[-1] not in [\".\", \"?\", \"!\"]:\n",
    "    # append a full-stop to sentences that do not end in punctuation\n",
    "    transcription = transcription + \".\"\n",
    "  \n",
    "  batch[\"sentence\"] = transcription\n",
    "  \n",
    "  chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "  batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
    "  \n",
    "  return {\"text\":batch[\"sentence\"], \"audio\":batch[\"audio\"][\"array\"]}\n",
    "  \n",
    "\n",
    "train_data = train_data.map(prepare_sentences, desc=\"prepare_sentences\", num_proc=16)\n",
    "test_data = test_data.map(prepare_sentences, desc=\"prepare_sentences\", num_proc=16)\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.remove_columns([\"sentence\"])\n",
    "test_data = test_data.remove_columns([\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering easier in pandas\n",
    "pd_train = train_data.to_pandas()\n",
    "pd_test = test_data.to_pandas()\n",
    "\n",
    "pattern = \"[^a-zA-ZáéíóúüñÁÉÍÓÚÜÑåäöÄÅÖ -'.,¿¡\\!?#<>:;\\\"]\"\n",
    "\n",
    "filt = pd_train[\"text\"].str.contains(pattern)\n",
    "pd_train = pd_train[~filt]\n",
    "pd_train = pd_train.reset_index(drop=True)\n",
    "\n",
    "filt = pd_test[\"text\"].str.contains(pattern)\n",
    "pd_test = pd_test[~filt]\n",
    "pd_test = pd_test.reset_index(drop=True)\n",
    "\n",
    "#train_data = Dataset.from_pandas(pd_train)\n",
    "#test_data = Dataset.from_pandas(pd_test)\n",
    "#print(train_data)\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5072256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd_train = train_data.to_pandas()\n",
    "pd_train[\"len\"] = pd_train[\"audio\"].map(len)\n",
    "longest_clip = pd_train.nlargest(1, columns=\"len\")[\"len\"].values[0]\n",
    "\n",
    "#pd_test = test_data.to_pandas()\n",
    "pd_test[\"len\"] = pd_test[\"audio\"].map(len)\n",
    "longest_clip_t = pd_test.nlargest(1, columns=\"len\")[\"len\"].values[0]\n",
    "\n",
    "if(longest_clip_t > longest_clip):\n",
    "    longest_clip = longest_clip_t\n",
    "longest_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_clip = 600000\n",
    "pd_train = pd_train.loc[pd_train['len'] < longest_clip] #about 10 sec\n",
    "pd_test = pd_test.loc[pd_test['len'] < longest_clip] #about 10 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, -1.494291886408594e-13, -2.1868214162244...</td>\n",
       "      <td>se trata de un sistema opuesto al sufragio dir...</td>\n",
       "      <td>245376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, -1.1187537983688156e-13, -4.856301450383...</td>\n",
       "      <td>el agua potable viene con un camión cisterna d...</td>\n",
       "      <td>249984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 2.966247039659642e-13, 2.234475625362275...</td>\n",
       "      <td>futaleufú en mapudungún significa gran río o r...</td>\n",
       "      <td>316800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 2.0469722108746452e-13, 9.94970707386688...</td>\n",
       "      <td>revista internacional</td>\n",
       "      <td>130176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.633123025918462e-13, -6.65785514827182...</td>\n",
       "      <td>una de las grúas cae seguida por la torre de p...</td>\n",
       "      <td>229248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28131</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>det finns även en order för gifta</td>\n",
       "      <td>207360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28132</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>hade ni kul då</td>\n",
       "      <td>164160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28133</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>smart tänkt</td>\n",
       "      <td>139968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28134</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>det var en stor svart katt med en vit fläck i ...</td>\n",
       "      <td>269568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28135</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>jag köpte en revolver och det var väl att jag ...</td>\n",
       "      <td>260928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   audio  \\\n",
       "0      [0.0, -1.494291886408594e-13, -2.1868214162244...   \n",
       "1      [0.0, -1.1187537983688156e-13, -4.856301450383...   \n",
       "2      [0.0, 2.966247039659642e-13, 2.234475625362275...   \n",
       "3      [0.0, 2.0469722108746452e-13, 9.94970707386688...   \n",
       "4      [0.0, 1.633123025918462e-13, -6.65785514827182...   \n",
       "...                                                  ...   \n",
       "28131  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "28132  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "28133  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "28134  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "28135  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                    text     len  \n",
       "0      se trata de un sistema opuesto al sufragio dir...  245376  \n",
       "1      el agua potable viene con un camión cisterna d...  249984  \n",
       "2      futaleufú en mapudungún significa gran río o r...  316800  \n",
       "3                                 revista internacional   130176  \n",
       "4      una de las grúas cae seguida por la torre de p...  229248  \n",
       "...                                                  ...     ...  \n",
       "28131                 det finns även en order för gifta   207360  \n",
       "28132                                    hade ni kul då   164160  \n",
       "28133                                       smart tänkt   139968  \n",
       "28134  det var en stor svart katt med en vit fläck i ...  269568  \n",
       "28135  jag köpte en revolver och det var väl att jag ...  260928  \n",
       "\n",
       "[28131 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_arr(batch):\n",
    "    audi = batch[\"audio\"]\n",
    "    padded = np.pad(audi, pad_width=(0, 600000 - len(audi)), mode='constant', constant_values=[0,0])\n",
    "    batch[\"audio\"] = padded\n",
    "    return batch\n",
    "pd_train = pd_train.apply(pad_arr, axis=1)\n",
    "pd_test = pd_test.apply(pad_arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n",
      "<jemalloc>: background thread creation failed (11)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "can't start new thread",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/coder/projects/Audio Translate/Embedded-Project/Speech2Text2.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_data \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mfrom_pandas(pd_train)\n\u001b[1;32m      <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test_data \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_pandas(pd_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m train_data\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:859\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    857\u001b[0m     info \u001b[39m=\u001b[39m DatasetInfo()\n\u001b[1;32m    858\u001b[0m info\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m features\n\u001b[0;32m--> 859\u001b[0m table \u001b[39m=\u001b[39m InMemoryTable\u001b[39m.\u001b[39;49mfrom_pandas(\n\u001b[1;32m    860\u001b[0m     df\u001b[39m=\u001b[39;49mdf,\n\u001b[1;32m    861\u001b[0m     preserve_index\u001b[39m=\u001b[39;49mpreserve_index,\n\u001b[1;32m    862\u001b[0m )\n\u001b[1;32m    863\u001b[0m \u001b[39mif\u001b[39;00m features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[39m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    865\u001b[0m     \u001b[39m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    866\u001b[0m     table \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39mcast(features\u001b[39m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/datasets/table.py:761\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    706\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pandas\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    707\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(pa\u001b[39m.\u001b[39;49mTable\u001b[39m.\u001b[39;49mfrom_pandas(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/pyarrow/table.pxi:3869\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/pyarrow/pandas_compat.py:622\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    620\u001b[0m             arrays\u001b[39m.\u001b[39mappend(convert_column(c, f))\n\u001b[1;32m    621\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m             arrays\u001b[39m.\u001b[39mappend(executor\u001b[39m.\u001b[39;49msubmit(convert_column, c, f))\n\u001b[1;32m    624\u001b[0m \u001b[39mfor\u001b[39;00m i, maybe_fut \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arrays):\n\u001b[1;32m    625\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_fut, futures\u001b[39m.\u001b[39mFuture):\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/concurrent/futures/thread.py:176\u001b[0m, in \u001b[0;36mThreadPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m w \u001b[39m=\u001b[39m _WorkItem(f, fn, args, kwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_work_queue\u001b[39m.\u001b[39mput(w)\n\u001b[0;32m--> 176\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adjust_thread_count()\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/concurrent/futures/thread.py:199\u001b[0m, in \u001b[0;36mThreadPoolExecutor._adjust_thread_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m thread_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_thread_name_prefix \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m,\n\u001b[1;32m    193\u001b[0m                          num_threads)\n\u001b[1;32m    194\u001b[0m t \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread(name\u001b[39m=\u001b[39mthread_name, target\u001b[39m=\u001b[39m_worker,\n\u001b[1;32m    195\u001b[0m                      args\u001b[39m=\u001b[39m(weakref\u001b[39m.\u001b[39mref(\u001b[39mself\u001b[39m, weakref_cb),\n\u001b[1;32m    196\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_work_queue,\n\u001b[1;32m    197\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initializer,\n\u001b[1;32m    198\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initargs))\n\u001b[0;32m--> 199\u001b[0m t\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads\u001b[39m.\u001b[39madd(t)\n\u001b[1;32m    201\u001b[0m _threads_queues[t] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_work_queue\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/threading.py:935\u001b[0m, in \u001b[0;36mThread.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     _limbo[\u001b[39mself\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m    934\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     _start_new_thread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bootstrap, ())\n\u001b[1;32m    936\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[39mwith\u001b[39;00m _active_limbo_lock:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: can't start new thread"
     ]
    }
   ],
   "source": [
    "train_data = Dataset.from_pandas(pd_train)\n",
    "test_data = Dataset.from_pandas(pd_test)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "  all_text = \" \".join(batch[\"text\"])\n",
    "  vocab = list(set(all_text))\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe32811bdc246ef8d2c7fe573fd0cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28136 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609767a56c6446d7b96edfda00aa26f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def max_sentence(batch):\n",
    "    leng = len(batch[\"text\"])\n",
    "    return {\"len\":leng}\n",
    "\n",
    "lengts = train_data.map(max_sentence, keep_in_memory=True)\n",
    "lengts_t = test_data.map(max_sentence, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.remove_columns([\"len\", '__index_level_0__'])\n",
    "test_data = test_data.remove_columns([\"len\", '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a77490810b94b578742e2a28e3c0303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61076a2411442609bc1befaa546cbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 'c',\n",
       " 1: 'v',\n",
       " 2: 'ú',\n",
       " 3: 's',\n",
       " 4: 'q',\n",
       " 5: 'k',\n",
       " 6: 'ä',\n",
       " 7: 'ñ',\n",
       " 8: 'p',\n",
       " 9: 'b',\n",
       " 10: 'g',\n",
       " 11: 't',\n",
       " 12: 'x',\n",
       " 13: 'n',\n",
       " 14: 'a',\n",
       " 15: 'e',\n",
       " 16: 'w',\n",
       " 17: 'á',\n",
       " 18: 'y',\n",
       " 19: 'å',\n",
       " 20: 'o',\n",
       " 21: 'i',\n",
       " 22: 'h',\n",
       " 23: ' ',\n",
       " 24: 'ö',\n",
       " 25: 'í',\n",
       " 26: 'f',\n",
       " 27: 'd',\n",
       " 28: 'r',\n",
       " 29: 'm',\n",
       " 30: 'j',\n",
       " 31: 'z',\n",
       " 32: \"'\",\n",
       " 33: 'u',\n",
       " 34: 'l',\n",
       " 35: 'ó'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_train = train_data.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=train_data.column_names)\n",
    "vocab_test = test_data.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=test_data.column_names)\n",
    "\n",
    "vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))\n",
    "vocab_dict = {k: v for k, v in enumerate(vocab_list)}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aasvocab_dict[36] = '-' #39\n",
    "asda\n",
    "vocab_dict[37] = '.' #40\n",
    "vocab_dict[38] = ',' #41\n",
    "vocab_dict[39] = '?' #42\n",
    "vocab_dict[40] = '!' #43\n",
    "vocab_dict[41] = '¡' #44\n",
    "vocab_dict[42] = '<' #45\n",
    "vocab_dict[43] = '>' #46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizeChar:\n",
    "    def __init__(self, max_len=50, vocab=None):\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, text):\n",
    "        text = text.lower()\n",
    "        text = text[: self.max_len - 2]\n",
    "        text = \"<\" + text.strip() + \">\"\n",
    "        pad_len = self.max_len - len(text)\n",
    "        return [list(self.vocab.values()).index(ch) for ch in text] + [list(self.vocab.values()).index(\" \")] * pad_len\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "def create_text_ds(data):\n",
    "    texts = data[\"text\"]\n",
    "    text_ds = [vectorizer(t) for t in texts]\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
    "    return text_ds\n",
    "\n",
    "\n",
    "def create_audio_ds(data):\n",
    "    audio_arr = data[\"audio\"]\n",
    "    \n",
    "    stfts = tf.signal.stft(audio_arr, frame_length=200, frame_step=80, fft_length=256)\n",
    "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
    "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
    "    x = (x - means) / stddevs\n",
    "    audio_ds = tf.data.Dataset.from_tensor_slices(x)\n",
    "    \n",
    "    return audio_ds\n",
    "\n",
    "\n",
    "def create_tf_dataset(data, bs=4):\n",
    "    audio_ds = create_audio_ds(data)\n",
    "    text_ds = create_text_ds(data)\n",
    "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
    "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
    "    ds = ds.batch(bs)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 44\n"
     ]
    }
   ],
   "source": [
    "sentece_len = np.max(lengts[\"len\"])\n",
    "sentece_len_t = np.max(lengts_t[\"len\"])\n",
    "\n",
    "max_target_len = sentece_len\n",
    "if(max_target_len < sentece_len_t):\n",
    "    max_target_len = sentece_len_t\n",
    "\n",
    "vectorizer = VectorizeChar(max_target_len, vocab_dict)\n",
    "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 14:03:18.667512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-12-09 14:03:18.667567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: embedded1\n",
      "2023-12-09 14:03:18.667574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: embedded1\n",
      "2023-12-09 14:03:18.667689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 530.30.2\n",
      "2023-12-09 14:03:18.667705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 530.30.2\n",
      "2023-12-09 14:03:18.667711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 530.30.2\n"
     ]
    }
   ],
   "source": [
    "ds = create_tf_dataset(train_data, bs=8)\n",
    "val_ds = create_tf_dataset(test_data, bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "class SpeechFeatureEmbedding(layers.Layer):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.conv3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"), # TODO go back to the wav and change this to than?\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
    "        return ffn_out_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid=64,\n",
    "        num_head=2,\n",
    "        num_feed_forward=128,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        num_layers_enc=4,\n",
    "        num_layers_dec=1,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source)\n",
    "        y = self.decode(x, target)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "            loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "        loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, batch, idx_to_token, target_start_token_idx=34, target_end_token_idx=35\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 != 0:\n",
    "            return\n",
    "        source = self.batch[\"source\"]\n",
    "        target = self.batch[\"target\"].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        print(\"\")\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i,:]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-','')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_lr=0.00001,\n",
    "        lr_after_warmup=0.001,\n",
    "        final_lr=0.00001,\n",
    "        warmup_epochs=15,\n",
    "        decay_epochs=85,\n",
    "        steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\"linear warm up - linear decay\"\"\"\n",
    "        warmup_lr = (\n",
    "            self.init_lr\n",
    "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / self.decay_epochs,\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        epoch = tf.cast(epoch, \"float32\")\n",
    "        return self.calculate_lr(epoch)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "        \"init_lr\" : self.init_lr\n",
    "        \"lr_after_warmup\" : self.lr_after_warmup\n",
    "        \"final_lr\" : self.final_lr\n",
    "        \"warmup_epochs\" : self.warmup_epochs\n",
    "        \"decay_epochs\" : self.decay_epochs\n",
    "        \"steps_per_epoch\" : self.steps_per_epoch\n",
    "        }\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "8/8 [==============================] - ETA: 0s - loss: 3.6526\n",
      "target:     <habita en aguas poco profundas y rocosas>                                                           \n",
      "prediction: <qkíqqqåxå>\n",
      "\n",
      "target:     <opera principalmente vuelos de cabotaje y regionales de carga>                                      \n",
      "prediction: <qkíqqqåxå>\n",
      "\n",
      "target:     <tres>                                                                                               \n",
      "prediction: <qkíqqqåxå>\n",
      "\n",
      "target:     <realizó los estudios primarios en francia para continuar luego en españa>                           \n",
      "prediction: <qkíqqqåxå>\n",
      "\n",
      "8/8 [==============================] - 29s 3s/step - loss: 3.6526 - val_loss: 3.3945\n",
      "Epoch 2/120\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.8396 - val_loss: 2.4228\n",
      "Epoch 3/120\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.1825 - val_loss: 2.0973\n",
      "Epoch 4/120\n",
      "8/8 [==============================] - 17s 2s/step - loss: 2.0119 - val_loss: 1.8738\n",
      "Epoch 5/120\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.8117 - val_loss: 1.7465\n",
      "Epoch 6/120\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.6787\n",
      "target:     <habita en aguas poco profundas y rocosas>                                                           \n",
      "prediction: <ta                                                                                                  \n",
      "\n",
      "target:     <opera principalmente vuelos de cabotaje y regionales de carga>                                      \n",
      "prediction: <ta                                                                                                  \n",
      "\n",
      "target:     <tres>                                                                                               \n",
      "prediction: <ta                                                                                                  \n",
      "\n",
      "target:     <realizó los estudios primarios en francia para continuar luego en españa>                           \n",
      "prediction: <ta                                                                                                  \n",
      "\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.6787 - val_loss: 1.6531\n",
      "Epoch 7/120\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.5903 - val_loss: 1.5830\n",
      "Epoch 8/120\n",
      "8/8 [==============================] - 17s 2s/step - loss: 1.5106 - val_loss: 1.5342\n",
      "Epoch 9/120\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.4537 - val_loss: 1.4959\n",
      "Epoch 10/120\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.4043 - val_loss: 1.4650\n",
      "Epoch 11/120\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.3633\n",
      "target:     <habita en aguas poco profundas y rocosas>                                                           \n",
      "prediction: <as                                                                                                  \n",
      "\n",
      "target:     <opera principalmente vuelos de cabotaje y regionales de carga>                                      \n",
      "prediction: <as                                                                                                  \n",
      "\n",
      "target:     <tres>                                                                                               \n",
      "prediction: <as                                                                                                  \n",
      "\n",
      "target:     <realizó los estudios primarios en francia para continuar luego en españa>                           \n",
      "prediction: <as                                                                                                  \n",
      "\n",
      "8/8 [==============================] - 19s 3s/step - loss: 1.3633 - val_loss: 1.4401\n",
      "Epoch 12/120\n",
      "2/8 [======>.......................] - ETA: 10s - loss: 1.6572"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/coder/projects/Audio Translate/Embedded-Project/Speech2Text2.ipynb Cell 37\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m optimizer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39mloss_fn)\n\u001b[0;32m---> <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(ds, validation_data\u001b[39m=\u001b[39;49mval_ds, callbacks\u001b[39m=\u001b[39;49m[display_cb], epochs\u001b[39m=\u001b[39;49m\u001b[39m120\u001b[39;49m)\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_ds))\n",
    "\n",
    "# The vocabulary to convert predicted indices into characters\n",
    "idx_to_char = vectorizer.get_vocabulary()\n",
    "display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=len(vectorizer.get_vocabulary())-2, target_end_token_idx=len(vectorizer.get_vocabulary())-1\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=200,\n",
    "    num_head=2,\n",
    "    num_feed_forward=400,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=4,\n",
    "    num_layers_dec=1,\n",
    "    num_classes=len(vectorizer.get_vocabulary()),\n",
    ")\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True\n",
    ")\n",
    "\n",
    "learning_rate = CustomSchedule(\n",
    "    init_lr=0.00001,\n",
    "    lr_after_warmup=0.001,\n",
    "    final_lr=0.00001,\n",
    "    warmup_epochs=45,\n",
    "    decay_epochs=125,\n",
    "    steps_per_epoch=len(ds),\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "history = model.fit(ds, validation_data=val_ds, shuffle=True, callbacks=[display_cb], epochs=1) # one to test saving for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and various"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "INFO:tensorflow:Assets written to: /home/coder/projects/Audio Translate/Embedded-Project/saved_models/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/coder/projects/Audio Translate/Embedded-Project/saved_models/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Learning rate schedule 'CustomSchedule' must override `get_config()` in order to be serializable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/coder/projects/Audio Translate/Embedded-Project/Speech2Text2.ipynb Cell 39\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m export_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(),\u001b[39m'\u001b[39m\u001b[39msaved_models\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://jth-ai-01.hj.se:50001/home/coder/projects/Audio%20Translate/Embedded-Project/Speech2Text2.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49msave(export_path)\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/projects/TEDS22/.conda/lib/python3.10/site-packages/keras/src/optimizers/schedules/learning_rate_schedule.py:83\u001b[0m, in \u001b[0;36mLearningRateSchedule.get_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39m@abc\u001b[39m\u001b[39m.\u001b[39mabstractmethod\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_config\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     84\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLearning rate schedule \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmust override `get_config()` in order to be serializable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Learning rate schedule 'CustomSchedule' must override `get_config()` in order to be serializable."
     ]
    }
   ],
   "source": [
    "export_path = os.path.join(os.getcwd(),'saved_models','model')\n",
    "model.save(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfoldersize(path):\n",
    "  total_size = 0\n",
    "  for dirpath, dirnames, filenames in os.walk(path):\n",
    "      for f in filenames:\n",
    "          fp = os.path.join(dirpath, f)\n",
    "          # skip if it is symbolic link\n",
    "          if not os.path.islink(fp):\n",
    "              total_size += os.path.getsize(fp)\n",
    "\n",
    "  total_size /= (1024 ** 3)\n",
    "  total_size = round(total_size, 3)\n",
    "  return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "old_model_size = getfoldersize(os.path.join(os.getcwd(),'data_rixvox'))\n",
    "#new_model_size = getfoldersize(os.path.join(os.getcwd(),'saved_tflite_models'))\n",
    "\n",
    "print(\"Old GB: \" + str(old_model_size))\n",
    "#print(\"New GB: \" + str(new_model_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
